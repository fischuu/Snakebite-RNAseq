---
title: "RNASeq-Pipeline report"
subtitle: "QC and basic stats"
author: "Daniel Fischer"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: true
    toc_depth: 4
    toc_float:
      toc_collapsed: true
    number_sections: true
    theme: lumen
    df_print: paged
    code_folding: show
---

```{r setup, include=FALSE}
#library("knitr")
library("GenomicTools")
library("Luke")
library("xtable")   # Needed for LaTeX output of the tables
library("viridis")  # Needed for the colouring of the plots
library("rjson")    # Needed for multiqc dgsb etail data
library("adegenet")
library("vcfR")
library("DT")
library("kableExtra")
library("ICS")
library("tsne")
library("lle")
library("kernlab")
#library("REPPlab")
#library("RDRToolbox")
library("destiny")  
options(scipen=999,
        stringsAsFactors=FALSE)
knitr::opts_chunk$set(echo = FALSE,
                      cache = FALSE,
                      cache.lazy = FALSE,
                      dev = c('png', 'pdf'),
                      fig.align = 'center', fig.height = 5, fig.width = 8.5)
if(!is.element("snakemake",ls())){
  projFolder <- "/scratch/project_2002561/MastitisChallenge/RNASeq-iSeq-Run2/"
  pipelineFolder <- "/scratch/project_2002561/pipeline/"
  pipelineConfig <- "/scratch/project_2002561/MastitisChallenge/RNASeq-iSeq-Run2/Pipeline-RNA-seq_config.yaml"
  refAnnot.file <- "/scratch/project_2002561/MastitisChallenge/RNASeq-iSeq-Run2/Reference/Bos_taurus.ARS-UCD1.2.100.gtf"
}
```

```{r help functions}
plotFastQCFeature <- function(x,y, labels=c("R1", "R2"), col=c(viridis(20)[8], viridis(20)[16]), feature="total_deduplicated_percentage", axes=TRUE){
  x.values <- as.vector(as.matrix(x[feature]))
  y.values <- as.vector(as.matrix(y[feature]))
  
  if(feature=="total_deduplicated_percentage"){
    label <- "De-Duplication level in %"
  } else if (feature=="X.GC"){
    label <- "GC content in %"
  } else if (feature=="avg_sequence_length"){
    label <- "Feature length"
  } else if (feature=="Total.Sequences"){
    label <- "Total sequences"
  }
  
  barplot(rbind(x.values, y.values), beside=TRUE, ylab=label, col=col)

  if(axes) axis(1, at=seq(2,3*nrow(x), by=3), paste(substr(x$Sample,1,10),"..."), las=2, cex=0.1)
  
  legend("bottomright", pch=c(20,20), col=col, legend=labels, fill="white")
}

plotFastQCJSONFeature <- function(x,y, labels, feature){
  par(mfrow=c(1,2))
  ymax <- max(rbind(x[feature][[1]],y[feature][[1]]))
  ymax <- ceiling(ymax+ymax*0.1)
  if(feature=="sequenceQuality") ymax <- 40
  boxplot(t(x[feature][[1]]), ylim=c(0,ymax))
  boxplot(t(y[feature][[1]]), ylim=c(0,ymax))
}

plotMQCFeature <- function(x, y, labels, feature){
  
  result1 <- fromJSON(file=file.path(x,"multiqc_data","multiqc_data.json"))
  result2 <- fromJSON(file=file.path(y,"multiqc_data","multiqc_data.json"))
  
  data1 <- get(feature, result1$report_plot_data)$datasets[[1]]
  data2 <- get(feature, result2$report_plot_data)$datasets[[1]]
  
  pos1 <-  length(sapply(data1,"[",2)[[1]]) - 1
  pos2 <-  length(sapply(data2,"[",2)[[1]]) - 1
  
  obs1 <- length(sapply(sapply(sapply(data1,"[",2),"[",1),"[",2))
  obs2 <- length(sapply(sapply(sapply(data2,"[",2),"[",1),"[",2))

  plotData1 <- matrix(-1, ncol=pos1, nrow=obs1)
  tmp <- sapply(sapply(data1,"[",2)[[1]],"[",1) 
  colnames(plotData1) <-  tmp[-length(tmp)]
  
  plotData2 <- matrix(-1, ncol=pos2, nrow=obs2)
  tmp <- sapply(sapply(data2,"[",2)[[1]],"[",1)
  colnames(plotData2) <- tmp[-length(tmp)]
  
  for(i in 1:pos1){
    writeThis <- sapply(sapply(sapply(data1,"[",2),"[",i),"[",2)
    writeThis[sapply(writeThis,is.null)] <- NA
    writeThis <- unlist(writeThis)
    plotData1[,i] <- writeThis
  }
  
  for(i in 1:pos2){
    writeThis <- sapply(sapply(sapply(data2,"[",2),"[",i),"[",2)
    writeThis[sapply(writeThis,is.null)] <- NA
    writeThis <- unlist(writeThis)
    plotData2[,i] <- writeThis
  }

  par(mfrow=c(1,2))
  ymax1 <- max(plotData1, na.rm=TRUE)
  ymax2 <- max(plotData2, na.rm=TRUE)
  ymax <- max(ymax1, ymax2)
  ymax <- ceiling(ymax+ymax*0.1)
  
  if(feature=="sequenceQuality") ymax <- 40
  boxplot(plotData1, ylim=c(0,ymax), pch=".", xaxt="n")
  #  axis(1,at=2:ncol(data1),gsub("X","",colnames(data1)[-1]))
  boxplot(plotData2, ylim=c(0,ymax), pch=".", xaxt="n")
  #  axis(1,at=2:ncol(data2),gsub("X","",colnames(data2)[-1]))
}

```


```{r help function 2}
getFastQCJSON <- function(path){
  
  x_file <- file.path(path)
  x <- fromJSON(paste(readLines(x_file), collapse=""))

  tmp <- x$report_plot_data$fastqc_per_base_sequence_quality_plot$datasets[[1]]
  datapoints <- length(tmp[[1]]$data)
  sequenceQuality <- matrix(-1, nrow= datapoints, ncol=length(tmp))
  rownames(sequenceQuality) <- sapply(tmp[[1]]$data,"[",1)
  for(i in 1:length(tmp)){
    sequenceQuality[,i] <- sapply(tmp[[i]]$data,"[",2)[1:datapoints]
  }  
  
  tmp <- x$report_plot_data$fastqc_per_base_n_content_plot$datasets[[1]]
  perBaseN <- matrix(-1, nrow= length(tmp[[1]]$data), ncol=length(tmp))
  rownames(perBaseN) <- sapply(tmp[[1]]$data,"[",1)
  for(i in 1:length(tmp)){
    perBaseN[,i] <- sapply(tmp[[i]]$data,"[",2)[1:datapoints]
  }
  
  output <- list(sequenceQuality=sequenceQuality,
                 perBaseN=perBaseN)
  output
}
```
# General workflow

## Directed acyclic graph (DAG)

The DAG of the used pipeline with rule dependencies.

```{r import workflow, echo=FALSE, fig.cap="Overview of the applied workflow", out.width = '100%'}
if(file.exists(file.path(projFolder,"workflow.png"))) knitr::include_graphics(file.path(projFolder,"workflow.png"))
```


# Basic stats

```{r get pipeline version}
pipeSMK <- readLines(file.path(pipelineFolder,"Snakefile-Pipeline-RNA-seq.smk"))
pipeVersion <- gsub("##### Version: ","",pipeSMK[grep("##### Version:", pipeSMK)])
```

```{r import barcodesID, results="asis"}
rawsamples <- read.table(file.path(projFolder, "rawsamples"))
samples <- read.table(file.path(projFolder, "samples"))
sampleInfo <- read.table(file.path(projFolder, "sampleInfo.txt"), header=TRUE)

out <- data.frame(c("Number of raw-samples",
                    "Number of samples (after concatenating)",
                    "No. of grouping information",
                    "Used Groups",
                    "Pipeline version"),
                  c(nrow(rawsamples),
                    nrow(samples),
                    ncol(sampleInfo)-1,
                    paste(colnames(sampleInfo)[-1],collapse=", "),
                    pipeVersion))

out_html <- knitr::kable(out, col.names = NULL, "html")
kable_styling(out_html, "striped", position = "left")
```

# FastQC quality checks

In this chapter the results from the FastQC part of the pipeline are presented. First, the basic stats on the very raw data are shown, then the concatenated (in case samples were split across different lanes) and then the final reads, after trimming.

After that, the concatenated reads are comapred against the trimmed reads.

```{r import multiqc data}
# Import the FastQC/MultiQC output for the RAW data
rawFastQC.R1 <- read.table(file.path(projFolder,"QC","RAW","multiqc_R1","multiqc_data","multiqc_fastqc.txt"), header=TRUE, sep="\t")
rawFastQC.R2 <- read.table(file.path(projFolder,"QC","RAW","multiqc_R2","multiqc_data","multiqc_fastqc.txt"), header=TRUE, sep="\t")
#rawFastQCJSON.R1 <- getFastQCJSON(file.path(projFolder, "QC", "RAW", "multiqc_R1", "multiqc_data", "multiqc_data.json"))
#rawFastQCJSON.R2 <- getFastQCJSON(file.path(projFolder, "QC", "RAW", "multiqc_R2", "multiqc_data", "multiqc_data.json"))

# Import the FastQC/MultiQC output for the CONCATENATED data
conFastQC.R1 <- read.table(file.path(projFolder,"QC","CONCATENATED","multiqc_R1","multiqc_data","multiqc_fastqc.txt"), header=TRUE, sep="\t")
conFastQC.R2 <- read.table(file.path(projFolder,"QC","CONCATENATED","multiqc_R2","multiqc_data","multiqc_fastqc.txt"), header=TRUE, sep="\t")
conFastQCJSON.R1 <- getFastQCJSON(file.path(projFolder, "QC", "CONCATENATED", "multiqc_R1", "multiqc_data", "multiqc_data.json"))
conFastQCJSON.R2 <- getFastQCJSON(file.path(projFolder, "QC", "CONCATENATED", "multiqc_R2", "multiqc_data", "multiqc_data.json"))

# Import the FastQC/MultiQC output for the TRIMMED data
trimmedFastQC.R1 <- read.table(file.path(projFolder,"QC","TRIMMED","multiqc_R1","multiqc_data","multiqc_fastqc.txt"), header=TRUE, sep="\t")
trimmedFastQC.R2 <- read.table(file.path(projFolder,"QC","TRIMMED","multiqc_R2","multiqc_data","multiqc_fastqc.txt"), header=TRUE, sep="\t")
trimmedFastQCJSON.R1 <- getFastQCJSON(file.path(projFolder, "QC", "TRIMMED", "multiqc_R1", "multiqc_data", "multiqc_data.json"))
trimmedFastQCJSON.R2 <- getFastQCJSON(file.path(projFolder, "QC", "TRIMMED", "multiqc_R2", "multiqc_data", "multiqc_data.json"))
```


## Raw data
These are the reads, as they come from the sequencer, no trimming, no nothing.

### De-duplication percent

```{r raw data duplication percent}
#par(mar=c(10,5,1,1))
plotFastQCFeature(rawFastQC.R1, rawFastQC.R2, feature="total_deduplicated_percentage", axes=FALSE)
abline(h=50, lty="dotted", col="red")
```

A list of samples over a certain threshold (>50%)

```{r table samples duplication under threshold raw}
tmp <- cbind(rawFastQC.R1$Sample,rawFastQC.R1["total_deduplicated_percentage"])
tmp <- tmp[tmp[,2]>50,]
if(nrow(tmp)>0){
rownames(tmp) <- 1:nrow(tmp)
colnames(tmp) <- c("Rawsample", "Total deduplicated percentage")

datatable(tmp)
}
```

### GC content

```{r raw data qc content}
#par(mar=c(10,5,1,1))
plotFastQCFeature(rawFastQC.R1, rawFastQC.R2, feature="X.GC", axes=FALSE)
abline(h=60, lty="dotted", col="red")
abline(h=30, lty="dotted", col="red")
```

A list of samples under a certain threshold (<30%)

```{r table samples GC content}
tmp <- cbind(rawFastQC.R1$Sample,rawFastQC.R1["X.GC"])
tmp <- tmp[tmp[,2]<30,]
if(nrow(tmp)>0){
  rownames(tmp) <- 1:nrow(tmp)
  colnames(tmp) <- c("Rawsample", "GC content")
  #knitr::kable(tmp) %>% kable_styling
  datatable(tmp)
}
```

### Sequence length

```{r raw data sequence length}
#par(mar=c(10,5,1,1))
plotFastQCFeature(rawFastQC.R1, rawFastQC.R2, feature="avg_sequence_length", axes=FALSE)
tmp <- rawFastQC.R1["avg_sequence_length"]
tmp <- mean(as.vector(as.matrix((tmp)))) 
abline(h=tmp*0.9, lty="dotted", col="red")
```

A list of samples with average sequence length smaller then overall average minus 10%.

```{r table samples sequence length}
tmp <- rawFastQC.R1["avg_sequence_length"]
tmp <- mean(as.vector(as.matrix((tmp)))) 
th <- tmp*0.9

tmp <- cbind(rawFastQC.R1$Sample,rawFastQC.R1["avg_sequence_length"])

tmp <- tmp[tmp[,2]<th,]
if(nrow(tmp)>0){
  rownames(tmp) <- 1:nrow(tmp)
  colnames(tmp) <- c("Rawsample", "Avg sequence length")
  #knitr::kable(tmp) %>% kable_styling
  datatable(tmp)
}
```

### Total sequences

```{r raw data total sequences}
#par(mar=c(10,5,1,1))
plotFastQCFeature(rawFastQC.R1, rawFastQC.R2, feature="Total.Sequences", axes=FALSE)
```

### Summary
```{r raw data summary stats}
mqcStats.raw <- read.table(file.path(projFolder,"QC","RAW","multiqc_R1", "multiqc_data", "multiqc_fastqc.txt"), header=TRUE, sep="\t")
tmp <- mqcStats.raw[,-c(1:4,7,11:21)]

totalRawSequences <- sum(mqcStats.raw$Total.Sequences)
out <- c(totalRawSequences,apply(tmp,2,mean))
names(out) <- c("Tot. number sequences",
                "Avg. total sequences",
                "Avg. poor quality",
                "Avg. GC Percent",
                "Avg. deplication percent",
                "Avg. sequence length")

out_html <- knitr::kable(out, col.names = NULL, "html")
kable_styling(out_html, "striped", position = "left")

out <- t(as.data.frame(as.matrix((summary(tmp[,1])))))
rownames(out) <- "5-point summary of total sequences"
out_html <- knitr::kable(out, "html")
kable_styling(out_html, "striped", position = "left")
```


## Concatenated data
In this section samples lanes are concatentated, but no other steps were performed.

### De-Duplication percent

```{r conc data duplication percent}
#par(mar=c(10,5,1,1))
plotFastQCFeature(conFastQC.R1, conFastQC.R2, feature="total_deduplicated_percentage", axes=FALSE)
abline(h=50, lty="dotted", col="red")
```

A list of samples over a certain threshold (>50%)

```{r table samples duplication under threshold conc}
tmp <- cbind(conFastQC.R1$Sample,conFastQC.R1["total_deduplicated_percentage"])
tmp <- tmp[tmp[,2]>50,]
if(nrow(tmp)>0){
rownames(tmp) <- 1:nrow(tmp)
colnames(tmp) <- c("Sample", "Total deduplicated percentage")

datatable(tmp)
}
```

### GC content

```{r conc data qc content}
#par(mar=c(10,5,1,1))
plotFastQCFeature(conFastQC.R1, conFastQC.R2, feature="X.GC", axes=FALSE)
abline(h=60, lty="dotted", col="red")
abline(h=30, lty="dotted", col="red")
```

A list of samples under a certain threshold (<30%)

```{r table samples GC content conc}
tmp <- cbind(conFastQC.R1$Sample,conFastQC.R1["X.GC"])
tmp <- tmp[tmp[,2]<30,]
if(nrow(tmp)>0){
  rownames(tmp) <- 1:nrow(tmp)
  colnames(tmp) <- c("Sample", "GC content")
  datatable(tmp)
}
```

### Sequence length

```{r con data sequence length}
#par(mar=c(10,5,1,1))
plotFastQCFeature(conFastQC.R1, conFastQC.R2, feature="avg_sequence_length", axes=FALSE)
tmp <- conFastQC.R1["avg_sequence_length"]
tmp <- mean(as.vector(as.matrix((tmp)))) 
abline(h=tmp*0.9, lty="dotted", col="red")
```

A list of samples with average sequence length smaller then overall average minus 10%.

```{r table samples sequence length conc}
tmp <- conFastQC.R1["avg_sequence_length"]
tmp <- mean(as.vector(as.matrix((tmp)))) 
th <- tmp*0.9

tmp <- cbind(conFastQC.R1$Sample, conFastQC.R1["avg_sequence_length"])

tmp <- tmp[tmp[,2]<th,]
if(nrow(tmp)>0){
  rownames(tmp) <- 1:nrow(tmp)
  colnames(tmp) <- c("Sample", "Avg sequence length")
  datatable(tmp)
}
```

### Total sequences

```{r con data total sequences}
par(mar=c(10,5,1,1))
plotFastQCFeature(conFastQC.R1, conFastQC.R2, feature="Total.Sequences")
```

### Per base N content (left: R1, right: R2)

```{r con data per base n content}
par(mar=c(5,5,1,1))
#plotFastQCJSONFeature(conFastQCJSON.R1, conFastQCJSON.R2, feature="perBaseN")

plotMQCFeature(x=file.path(projFolder,"QC","CONCATENATED","multiqc_R1"),
               y=file.path(projFolder,"QC","CONCATENATED","multiqc_R2"),
               feature="fastqc_per_base_n_content_plot")
```

### Per base quality (left: R1, right: R2)
```{r con data per base sequence quality}
par(mar=c(5,5,1,1))
#plotFastQCJSONFeature(conFastQCJSON.R1, conFastQCJSON.R2, feature="sequenceQuality")

plotMQCFeature(x=file.path(projFolder,"QC","CONCATENATED","multiqc_R1"),
               y=file.path(projFolder,"QC","CONCATENATED","multiqc_R2"),
               feature="fastqc_per_base_sequence_quality_plot")
```

### Summary
```{r conc data summary stats}
mqcStats.conc <- read.table(file.path(projFolder,"QC","CONCATENATED","multiqc_R1", "multiqc_data", "multiqc_fastqc.txt"), header=TRUE, sep="\t")
tmp <- mqcStats.conc[,-c(1:4,7,11:21)]

totalConcSequences <- sum(mqcStats.conc$Total.Sequences)
out <- c(totalConcSequences,apply(tmp,2,mean))
names(out) <- c("Tot. number sequences",
                "Avg. total sequences",
                "Avg. poor quality",
                "Avg. GC Percent",
                "Avg. deplication percent",
                "Avg. sequence length")

out_html <- knitr::kable(out, col.names = NULL, "html")
kable_styling(out_html, "striped", position = "left")

out <- t(as.data.frame(as.matrix((summary(tmp[,1])))))
rownames(out) <- "5-point summary of total sequences"
out_html <- knitr::kable(out, "html")
kable_styling(out_html, "striped", position = "left")
```


## Trimmed data

### De-Duplication percent

```{r trimmed data duplication percent}
#par(mar=c(10,5,1,1))
plotFastQCFeature(trimmedFastQC.R1, trimmedFastQC.R2, feature="total_deduplicated_percentage", axes=FALSE)
abline(h=50, lty="dotted", col="red")
```

A list of samples over a certain threshold (>50%)

```{r table samples duplication under threshold trimmed}
tmp <- cbind(trimmedFastQC.R1$Sample,trimmedFastQC.R1["total_deduplicated_percentage"])
tmp <- tmp[tmp[,2]>50,]
if(nrow(tmp)>0){
rownames(tmp) <- 1:nrow(tmp)
colnames(tmp) <- c("Sample", "Total deduplicated percentage")

datatable(tmp)
}
```

### QC content

```{r trimmed data qc content}
#par(mar=c(10,5,1,1))
plotFastQCFeature(trimmedFastQC.R1, trimmedFastQC.R2, feature="X.GC", axes=FALSE)
abline(h=60, lty="dotted", col="red")
abline(h=30, lty="dotted", col="red")
```

A list of samples under a certain threshold (<30%)

```{r table samples GC content trimmed}
tmp <- cbind(trimmedFastQC.R1$Sample, trimmedFastQC.R1["X.GC"])
tmp <- tmp[tmp[,2]<30,]
if(nrow(tmp)>0){
  rownames(tmp) <- 1:nrow(tmp)
  colnames(tmp) <- c("Sample", "GC content")
  #knitr::kable(tmp) %>% kable_styling
  datatable(tmp)
}
```
### Sequence length

```{r trimmed data sequence length}
#par(mar=c(10,5,1,1))
plotFastQCFeature(trimmedFastQC.R1, trimmedFastQC.R2, feature="avg_sequence_length", axes=FALSE)
tmp <- trimmedFastQC.R1["avg_sequence_length"]
tmp <- mean(as.vector(as.matrix((tmp)))) 
abline(h=tmp*0.9, lty="dotted", col="red")
```

A list of samples with average sequence length smaller then overall average minus 10%.

```{r table samples sequence length trimmed}
tmp <- trimmedFastQC.R1["avg_sequence_length"]
tmp <- mean(as.vector(as.matrix((tmp)))) 
th <- tmp*0.9

tmp <- cbind(trimmedFastQC.R1$Sample, trimmedFastQC.R1["avg_sequence_length"])

tmp <- tmp[tmp[,2]<th,]
if(nrow(tmp)>0){
  rownames(tmp) <- 1:nrow(tmp)
  colnames(tmp) <- c("Sample", "Avg sequence length")
  #knitr::kable(tmp) %>% kable_styling
  datatable(tmp)
}
```

### Total sequences

```{r trimmed data total sequences}
par(mar=c(10,5,1,1))
plotFastQCFeature(trimmedFastQC.R1, trimmedFastQC.R2, feature="Total.Sequences")
```

### Per base N content

```{r trimmed data per base n content}
par(mar=c(5,5,1,1))
#plotFastQCJSONFeature(conFastQCJSON.R1, conFastQCJSON.R2, feature="perBaseN")

plotMQCFeature(x=file.path(projFolder,"QC","TRIMMED","multiqc_R1"),
               y=file.path(projFolder,"QC","TRIMMED","multiqc_R2"),
               feature="fastqc_per_base_n_content_plot")
```

### Per base quality (left: R1, right: R2)
```{r trimmed data per base sequence quality}
par(mar=c(5,5,1,1))
#plotFastQCJSONFeature(conFastQCJSON.R1, conFastQCJSON.R2, feature="sequenceQuality")

plotMQCFeature(x=file.path(projFolder,"QC","TRIMMED","multiqc_R1"),
               y=file.path(projFolder,"QC","TRIMMED","multiqc_R2"),
               feature="fastqc_per_base_sequence_quality_plot")
```


### Length distribution trimmed reads
From the trimlog we get more statistics on the output of the trimming. Include the trimlog data also here as density plots.

THESE COME FROM THE FILES: ./logs/cutadapt*

### Summary
```{r trimmed data summary stats}
mqcStats.trim <- read.table(file.path(projFolder,"QC","TRIMMED","multiqc_R1", "multiqc_data", "multiqc_fastqc.txt"), header=TRUE, sep="\t")
tmp <- mqcStats.trim[,-c(1:4,7,11:21)]

totalTrimSequences <- sum(mqcStats.trim$Total.Sequences)
out <- c(totalTrimSequences,apply(tmp,2,mean))
names(out) <- c("Tot. number sequences",
                "Avg. total sequences",
                "Avg. poor quality",
                "Avg. GC Percent",
                "Avg. deplication percent",
                "Avg. sequence length")

out_html <- knitr::kable(out, col.names = NULL, "html")
kable_styling(out_html, "striped", position = "left")

out <- t(as.data.frame(as.matrix((summary(tmp[,1])))))
rownames(out) <- "5-point summary of total sequences"
out_html <- knitr::kable(out, "html")
kable_styling(out_html, "striped", position = "left")

```


## Concatenated vs. Trimmed

```{r average trimmed and conc}
conFastQC.avg <- (conFastQC.R1[,-c(1:4,7,11:21)] + conFastQC.R2[,-c(1:4,7,11:21)]) / 2
trimmedFastQC.avg <- (trimmedFastQC.R1[,-c(1:4,7,11:21)] + trimmedFastQC.R2[,-c(1:4,7,11:21)]) / 2
conFastQC.avg$Sample <- conFastQC.R1$Sample
trimmedFastQC.avg$Sample <- trimmedFastQC.R1$Sample

conFastQCJSON.avg <- list()
conFastQCJSON.avg$sequenceQuality <- (conFastQCJSON.R1$sequenceQuality + conFastQCJSON.R2$sequenceQuality)/2
conFastQCJSON.avg$perBaseN <- (conFastQCJSON.R1$perBaseN + conFastQCJSON.R2$perBaseN)/2
trimmedFastQCJSON.avg <- list()
#trimmedFastQCJSON.avg$sequenceQuality <- (trimmedFastQCJSON.R1$sequenceQuality + trimmedFastQCJSON.R2$sequenceQuality)/2
#trimmedFastQCJSON.avg$perBaseN <- (trimmedFastQCJSON.R1$perBaseN + trimmedFastQCJSON.R2$perBaseN)/2
trimmedFastQCJSON.avg$sequenceQuality <- trimmedFastQCJSON.R1$sequenceQuality
trimmedFastQCJSON.avg$perBaseN <- trimmedFastQCJSON.R1$perBaseN
```

### De-Duplication percent

```{r conctrim data duplication percent}
par(mar=c(10,5,1,1))
plotFastQCFeature(conFastQC.avg, trimmedFastQC.avg, labels=c("Conc", "Trimmed"), feature="total_deduplicated_percentage")
```

### GC content

```{r conctrim data qc content}
par(mar=c(10,5,1,1))
plotFastQCFeature(conFastQC.avg, trimmedFastQC.avg, labels=c("Conc", "Trimmed"), feature="X.GC")
```

### Sequence length

```{r conctrim data sequence length}
par(mar=c(10,5,1,1))
plotFastQCFeature(conFastQC.avg, trimmedFastQC.avg, labels=c("Conc", "Trimmed"), feature="avg_sequence_length")
```

### Total sequences

```{r conctrim data total sequences}
par(mar=c(10,5,1,1))
plotFastQCFeature(conFastQC.avg, trimmedFastQC.avg, labels=c("Conc", "Trimmed"), feature="Total.Sequences")
```

### Per base N content (left: Conc., right: Trimmed)
```{r contrimm data per base n content}
par(mar=c(5,5,1,1))
#plotFastQCJSONFeature(conFastQCJSON.R1, conFastQCJSON.R2, feature="perBaseN")

plotMQCFeature(x=file.path(projFolder,"QC","CONCATENATED","multiqc_R1"),
               y=file.path(projFolder,"QC","TRIMMED","multiqc_R1"),
               feature="fastqc_per_base_n_content_plot")
```

### Per base quality (left: R1, right: R2)
```{r contrimm data per base sequence quality}
par(mar=c(5,5,1,1))
#plotFastQCJSONFeature(conFastQCJSON.R1, conFastQCJSON.R2, feature="sequenceQuality")

plotMQCFeature(x=file.path(projFolder,"QC","CONCATENATED","multiqc_R1"),
               y=file.path(projFolder,"QC","TRIMMED","multiqc_R1"),
               feature="fastqc_per_base_sequence_quality_plot")
```


# Analyses preparations

## Quantifications (RSEM)
We import the transcript quantification from RSEM and base the PCA plots on those

```{r, warning=FALSE}
tmp <- list.files(file.path(projFolder,"RSEM"), pattern="*.isoforms.results",)
rsem.transcripts <- fread(file.path(projFolder,"RSEM", tmp[1]))
rsem.transcripts <- rsem.transcripts[,c("transcript_id", "TPM")]
colnames(rsem.transcripts)[2] <- paste0(gsub(".isoforms.results","",tmp[1]),"-TPM")

for(i in 2:length(tmp)){
#for(i in 2:10){
  rsem.transcripts.tmp <- fread(file.path(projFolder,"RSEM", tmp[i]))
  rsem.transcripts.tmp <- rsem.transcripts.tmp[,c("transcript_id", "TPM")]
  colnames(rsem.transcripts.tmp)[2] <- paste0(gsub(".isoforms.results","",tmp[i]),"-TPM")
  rsem.transcripts <- merge(rsem.transcripts, rsem.transcripts.tmp, by="transcript_id")
}

if(sum(colnames(rsem.transcripts[,-1])==paste0(sampleInfo[,1],"-TPM"))!=nrow(sampleInfo)){
  warning("Sample quantification order does not match the sample metainformation order!!! Check that!!!")
  
  sampleInfo.bak <- sampleInfo
  
  for(i in 2:ncol(rsem.transcripts)){
    newOrder <- which(colnames(rsem.transcripts)[i]==paste0(sampleInfo.bak[,1],"-TPM"))
    sampleInfo[i-1,] <- sampleInfo.bak[newOrder,]
  }
  
} 
```

Remove low expressed features

```{r}
rsem.transcripts.meanexp <- apply(rsem.transcripts[,-1],1,mean)
rsem.transcripts <- rsem.transcripts[rsem.transcripts.meanexp>1,]
```

Now we create the quantile normalized expression matrix. That way we rely only on ranks, not on the true expressions, in fact.
```{r}
# Determine the ranks per sample
  rsem.transcripts.rank <- apply(rsem.transcripts[,-1],2,rank,ties.method="min")
# Sort the observations 
  rsem.transcripts.sorted <- data.frame(apply(rsem.transcripts[,-1], 2, sort))
# Calculate the means per sorted feature (mean of all the smallest, second smallest etc)
  rsem.transcripts.mean <- apply(rsem.transcripts.sorted, 1, mean)
# Substitute the ranks with the average expression value
  index_to_mean <- function(my_index, my_mean){
    return(my_mean[my_index])
  }
  rsem.transcripts.qn <- apply(rsem.transcripts.rank, 2, index_to_mean, my_mean=rsem.transcripts.mean)
```

## Quantification (featureCounts)

We import the feature counts data together with the annotation to get the biotype distribution of the data.

First some general stats about the used reference genome annotation

```{r}
annotation <- importGTF(refAnnot.file)
```

Following numbers of various annotations per biotype are available inside annotaiton file

```{r}
out_html <- knitr::kable(table(annotation$gene_biotype), col.names = NULL, "html")
kable_styling(out_html, "striped", position = "left")
``` 

Import the featureCOunts quantification

```{r}
fc.files <- list.files(file.path(projFolder, "FeatureCounts", "Annot"), pattern="*.txt$")
fc.in <- list()
for(i in 1:length(fc.files)){
  fc.in[[i]] <- importFeatureCounts(file.path(projFolder, "FeatureCounts", "Annot", fc.files[i]))
}

fc.expr.star <- merge(fc.in[[1]]$expValues, fc.in[[2]]$expValues, by="Geneid")

for(i in 3:length(fc.files)){
  fc.expr.star <- merge(fc.expr.star, fc.in[[i]]$expValues, by="Geneid")
}
colnames(fc.expr.star) <- sub(".*?Reference.", "",colnames(fc.expr.star))
colnames(fc.expr.star) <- sub("_reference_star.bam", "",colnames(fc.expr.star))
```
Now get the counts per biotype per sample

```{r}
biotypes <- names(table(annotation$gene_biotype))

counts_per_biotype <- matrix(0, ncol=ncol(fc.expr.star)-1, nrow=length(biotypes))
rownames(counts_per_biotype) <- biotypes
colnames(counts_per_biotype) <- colnames(fc.expr.star)[-1]

for(i in 1:length(biotypes)){
  biotype.genes <- annotation$gene_id[annotation$gene_biotype==biotypes[i]]
  counts_per_biotype[i,] <- apply(fc.expr.star[is.element(fc.expr.star$Geneid, biotype.genes),-1],2,sum)
}
```

```{r}
out_html <- knitr::kable(counts_per_biotype, "html")
kable_styling(out_html, "striped", position = "left")
```

```{r}
out_html <- knitr::kable(round(t(t(counts_per_biotype)/apply(counts_per_biotype,2,sum))*100,2), "html")
kable_styling(out_html, "striped", position = "left")
```

And a summary table of the percentages

```{r}
tmp <- round(t(t(counts_per_biotype)/apply(counts_per_biotype,2,sum))*100,2)
out_html <- knitr::kable(t(apply(tmp,1,summary)), "html")
kable_styling(out_html, "striped", position = "left")
```

# Clustering

## Hierarchical Clustering
First we perform a hierarchical clustering, using the euclidean distances of the RSEM transcript values as distance measure

```{r}
#rsem.transcripts.dist <- dist(as.matrix(t(rsem.transcripts[,-1])))
rsem.transcripts.dist <- as.dist(1-cor(as.matrix(rsem.transcripts[,-1])))
hc <- hclust(rsem.transcripts.dist)           
plot(hc)  
```

And the same for the quantile normalised RSEM transcript values

```{r}
#rsem.transcripts.qn.dist <- dist(as.matrix(t(rsem.transcripts.qn)))
rsem.transcripts.qn.dist <- as.dist(1-cor(as.matrix(rsem.transcripts.qn)))
hc <- hclust(rsem.transcripts.qn.dist)           
plot(hc)  
```

# Dimension Reduction

## PCA
```{r performPCA}
expr.PCA <- prcomp(t(rsem.transcripts[,-1]))
```

This is just the plain PCA, without using any colouring schemes.

```{r}
palette("default")
pairs(expr.PCA$x[,1:3])
```

```{r}
names(expr.PCA$x[,1])[which(expr.PCA$x[,1]>0)]
```

```{r, results="asis"}
if(ncol(sampleInfo)>1){
for(i in 2:ncol(sampleInfo)){
  tmpTitle <- paste("### 3C: ",colnames(sampleInfo)[i],"\n")
  cat(sprintf(tmpTitle))
  pairs(expr.PCA$x[,1:3], col=as.numeric(as.factor(sampleInfo[,i])), pch=20, oma=c(3,3,3,15))
  par(xpd=TRUE)
  legend("bottomright", fill=as.factor(levels(as.factor(sampleInfo[,i]))), legend=levels(as.factor(sampleInfo[,i])))
  par(xpd=FALSE)
  cat(sprintf("\n\n"))
}
}
```

```{r}
cols <- min(ncol(expr.PCA$x),10)
pairs(expr.PCA$x[,1:cols])
```

```{r, results="asis"}
if(ncol(sampleInfo)>1){
for(i in 2:ncol(sampleInfo)){
  tmpTitle <- paste("### 10C: ",colnames(sampleInfo)[i],"\n")
  cat(sprintf(tmpTitle))
  pairs(expr.PCA$x[,1:cols], col=as.numeric(as.factor(sampleInfo[,i])), pch=20, oma=c(3,3,3,15))
  par(xpd=TRUE)
  legend("bottomright", fill=as.factor(levels(as.factor(sampleInfo[,i]))), legend=levels(as.factor(sampleInfo[,i])))
  par(xpd=FALSE)
  cat(sprintf("\n\n"))
}
}
```

## ICS
```{r, results="asis"}
cols <- min(ncol(expr.PCA$x),10)
FOBI <- ics(expr.PCA$x[,1:cols])
if(ncol(sampleInfo)>1){
for(i in 2:ncol(sampleInfo)){
  tmpTitle <- paste("### ",colnames(sampleInfo)[i],"\n")
  cat(sprintf(tmpTitle))
  plot(FOBI, col=as.numeric(as.factor(sampleInfo[,i])), pch=20, oma=c(3,3,3,15))
  par(xpd=TRUE)
  legend("bottomright", fill=as.factor(levels(as.factor(sampleInfo[,i]))), legend=levels(as.factor(sampleInfo[,i])))
  par(xpd=FALSE)
  cat(sprintf("\n\n"))
}  
} else {
   plot(FOBI, pch=20)
}

```

## t-SNE
```{r, results="asis"}
cols <- min(ncol(expr.PCA$x),10)
TSNEout <- tsne(expr.PCA$x[,1:cols], k=5)

if(ncol(sampleInfo)>1){
for(i in 2:ncol(sampleInfo)){
  tmpTitle <- paste("### ",colnames(sampleInfo)[i],"\n")
  cat(sprintf(tmpTitle))
  plot(TSNEout, col=as.numeric(as.factor(sampleInfo[,i])), pch=20, oma=c(3,3,3,15))
  par(xpd=TRUE)
  legend("bottomright", fill=as.factor(levels(as.factor(sampleInfo[,i]))), legend=levels(as.factor(sampleInfo[,i])))
  par(xpd=FALSE)
  cat(sprintf("\n\n"))
}
} else {
   plot(TSNEout, pch=20)
}
```

## Kernel PCA
```{r}
# Kernel PCA
cols <- min(min(dim(expr.PCA$x)),10)-1

KPCAres <- kpca(expr.PCA$x[,1:cols])
```

```{r, results="asis"}
if(ncol(sampleInfo)>1){
  for(i in 2:ncol(sampleInfo)){
      tmpTitle <- paste("### ",colnames(sampleInfo)[i],"\n")
      cat(sprintf(tmpTitle))
      pairs(rotated(KPCAres)[,1:cols], col=as.numeric(as.factor(sampleInfo[,i])), pch=20, oma=c(3,3,3,15))
      par(xpd=TRUE)
      legend("bottomright", fill=as.factor(levels(as.factor(sampleInfo[,i]))), legend=levels(as.factor(sampleInfo[,i])))
      par(xpd=FALSE)
      cat(sprintf("\n\n"))
  }

} else {
   ndim <- min(ncol(rotated(KPCAres)), 10)
   plot(rotated(KPCAres)[,1:ndim], pch=20)
}

```

## Diffusion map
```{r, results="asis"}
# Diffusion map
#  dm <- DiffusionMap(expr.PCA$x[,1:10])
#  for(i in 2:ncol(sampleInfo)){
#     pairs(dm@eigenvectors[,1:10], col=as.numeric(as.factor(sampleInfo[,i])), pch=20)
#  }
```

## Locally linear embedding (LLE)
```{r}
# LLE
cols <- min(ncol(expr.PCA$x),10)

lleres <- lle(expr.PCA$x[,1:cols], m=7, k=17, v=0.99)
```

```{r, results="asis"}
  if(ncol(sampleInfo)>1){
  for(i in 2:ncol(sampleInfo)){
      tmpTitle <- paste("### ",colnames(sampleInfo)[i],"\n")
      cat(sprintf(tmpTitle))
      pairs(lleres$Y[,1:5], col=as.numeric(as.factor(sampleInfo[,i])), pch=20, oma=c(3,3,3,15))
      par(xpd=TRUE)
      legend("bottomright", fill=as.factor(levels(as.factor(sampleInfo[,i]))), legend=levels(as.factor(sampleInfo[,i])))
      par(xpd=FALSE)
      cat(sprintf("\n\n"))
  }

} else {
   plot(lleres$Y[,1:5], pch=20)
}
```

```{r}
# REPPlab
#  REPPres <- EPPlab(x.pca[,1:5], PPalg = "Tribe", PPindex = "KurtosisMin", n.simu = 100, maxiter = 200, sphere = TRUE)
#  plot(REPPres, type = "angles", which = 1:100)
#  pairs(REPPres, which = c(60, 80,100))
  
```

# Case/Control Analysis
In case there is a casecontrol column in the file sampleInfo.txt we perform a DE analysis between cases and controls.

TODO!!!!

# Warnings and Issues
Here we add some automatic checks of the pipeline and the data and report possible problems

```{r}
conc.test <- "FAILED"
if(totalRawSequences==totalConcSequences) conc.test <- "PASS"

out <- data.frame(c("Concatenation (number of sequences)"),
                  c(conc.test))
colnames(out) <- c("Test", "Result")
out_html <- knitr::kable(out, "html")
kable_styling(out_html, "striped", position = "left") 
```

# Benchmarks

## Runtimes per calculation step
IMPORT HERE STILL THE BENCHMARKING TABLES

# Appendix

## Project Setup

## Pipeline configuration
This is the configuration file that is used for the project:

```{r import config file}
configFile <- readLines(pipelineConfig)
```

```{r print configuration}
  out_html <- knitr::kable(as.matrix(configFile), "html")
  kable_styling(out_html, "striped", position = "left")
```